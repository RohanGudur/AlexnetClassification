# -*- coding: utf-8 -*-
"""Alexnets .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GAWkxDA-RWQjlmiTYLO0sudnVdD37v4m
"""

import torch
import torchvision
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision import transforms
from torchvision.transforms import ToTensor, RandomAffine, RandomHorizontalFlip

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

transform_augmented = transforms.Compose([transforms.Resize(64),
    transforms.CenterCrop(224),
    transforms.ToTensor()])
train_dataset= datasets.CIFAR10(root='data', train=True,
                                download=True,
                                transform=transform_augmented)
test_dataset = datasets.CIFAR10(root='data',
                             train=False,
                             download=True,
                             transform=transform_augmented)

#DataAugmentation

class_names=train_dataset.classes
train_dataset.class_to_idx

train_dataset.data.shape

len(train_dataset)
image,label = train_dataset[0]

image.shape,label
#    train_dataset is a dataset object that contains both the images and labels.
# train_dataset.data is a tensor containing only the image data without labels.

len(test_dataset)
image,label =test_dataset[0]
image.shape,label

import matplotlib.pyplot as plt
plt.imshow(train_dataset.data[0], cmap='gray')
plt.title('%i' % train_dataset.targets[0])
plt.show()

from torch.utils.data import DataLoader
#deciding batch size
batch_size=64

train_dataloader= DataLoader(dataset=train_dataset,
                             batch_size=int(batch_size),
                             shuffle=True)

test_dataloader= DataLoader(dataset=test_dataset,
                            batch_size=int(batch_size),
                            shuffle=False)

print(f"Dataloaders: {train_dataloader, test_dataloader}")
print(f"Length of train dataloader: {len(train_dataloader)} batches of {batch_size}")
print(f"Length of test dataloader: {len(test_dataloader)} batches of {batch_size}")

train_image , train_labels = next(iter(train_dataloader))
train_image.shape,train_labels.shape

import torchvision.models as models
alexnet = models.alexnet(pretrained=True)

image.shape

len(train_dataloader)
print(len(train_dataloader))

def train(model, train_dataloader, num_epochs, lr, checkpoint_path='model_checkpoint.pth'):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    loss_func = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    loss_values = []

    for epoch in range(num_epochs):
        for i, (images, labels) in enumerate(train_dataloader):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            output = model(images)
            loss = loss_func(output, labels)
            loss.backward()
            optimizer.step()

            if (i+1) % batch_size == 0:
                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                       .format(epoch + 1, num_epochs, i + 1, len(train_dataloader), loss.item()))

                loss_values.append(loss.item())

        checkpoint = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss_values': loss_values,
        }
        torch.save(checkpoint, checkpoint_path)

    plt.plot(loss_values)
    plt.title('Training Loss')
    plt.xlabel('Step')
    plt.ylabel('Loss')
    plt.show()


train(alexnet, train_dataloader, num_epochs=4, lr=0.0001, checkpoint_path='model_checkpoint.pth')

!nvidia-smi
# if connected to gpu

def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = range(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    for i in range(len(classes)):
        for j in range(len(classes)):
            plt.text(j, i, str(cm[i, j]), ha='center', va='center', color='white' if cm[i, j] > cm.max() / 2 else 'black')

    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc

def test(model, test_dataloader):
    # Test the model
    model.eval()
    with torch.no_grad():
        correct = 0
        total = 0
        all_preds = torch.tensor([], dtype=torch.long, device=device)
        all_labels = torch.tensor([], dtype=torch.long, device=device)

        for images, labels in test_dataloader:
            images, labels = images.to(device), labels.to(device)

            test_output = model(images)
            _, pred_y = torch.max(test_output, 1)

            total += labels.size(0)
            correct += (pred_y == labels).sum().item()

            # Store predicted labels and true labels
            all_preds = torch.cat((all_preds, pred_y), dim=0)
            all_labels = torch.cat((all_labels, labels), dim=0)

        accuracy = correct * 100 / total
        print('Test Accuracy of the model on the test dataset: {:.2f}%'.format(accuracy))

        # Calculate precision, recall, sensitivity, specificity, F1 score
        print('\nClassification Report:')
        overall_metrics = classification_report(all_labels.cpu().numpy(), all_preds.cpu().numpy(), output_dict=True)
        print(overall_metrics)
                # Extract overall precision, recall, and F1-score
        macro_precision = overall_metrics['macro avg']['precision']
        macro_recall = overall_metrics['macro avg']['recall']
        macro_f1 = overall_metrics['macro avg']['f1-score']

        print('Overall Metrics:')
        print('Macro-Averaged Precision: {:.4f}'.format(macro_precision))
        print('Macro-Averaged Recall: {:.4f}'.format(macro_recall))
        print('Macro-Averaged F1-Score: {:.4f}'.format(macro_f1))

        # Confusion matrix
        print('\nConfusion Matrix:')
        cm=confusion_matrix(all_labels.cpu().numpy(), all_preds.cpu().numpy())
        plot_confusion_matrix(cm, classes=class_names)


test(alexnet,test_dataloader)